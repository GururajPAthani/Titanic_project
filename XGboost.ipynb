{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDA_XGBoost(xgb_table_1) :\n",
    "    ##DropColumns if necessary\n",
    "    xgb_table=xgb_table_1.drop(['Cabin'],axis=1)\n",
    "    #Find Invalid/Null Values\n",
    "    print(\"XGBoost EDA output shape = \",xgb_table.isna().sum())\n",
    "    xgb_table=xgb_table.dropna()\n",
    "    print(\"XGBoost       : EDA - Complete\")\n",
    "    return(xgb_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureEngineering_XGBoost(df_xcb_fe) :\n",
    "\n",
    "    ## Feature Selection (\"Drop/Multipy/Create new features/predictors if needed\")\n",
    "    print(\"XGBoost     : Feature Engineering \\n\")\n",
    "\n",
    "    print(\"Selected predictors for transformation\\n\")\n",
    "    #Feature transformation \n",
    "    #Convert to string (change datatype)\n",
    "    df_xcb_fe['Pclass']= df_xcb_fe['Pclass'].astype('str')  \n",
    "    #Dummy encode the data\n",
    "    df_xcb_fe = pd.get_dummies(df_xcb_fe,drop_first=True)\n",
    "    print(\"Check if categorical variables are in string or dummy encoded \\n\",df_xcb_fe.columns,\"\\n\")\n",
    "\n",
    "    #Feature Selection\n",
    "    #Based on the correlation Matrix\n",
    "    # Fare has significan positive correlation on Survival\n",
    "    # Sex_male and Pclass has significant negative correlation on survival\n",
    "    # So lets select Fare and Sex_Male for our modelling\n",
    "    #df_xcb_fe_selected = df_xcb_fe.drop(['Embarked_S'],axis=1)\n",
    "    df_xcb_fe_selected = df_xcb_fe\n",
    "    print(\"Selected predictors for modelling \\n\")\n",
    "    print(df_xcb_fe_selected.info(),\"\\n\")\n",
    "    return(df_xcb_fe_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HyperParameterTuning_XGBoost() :\n",
    "    print('XGBoost       : Hyperparameter Tuning')\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    xcb_cv = XGBClassifier(random_state=0)\n",
    "    #param_cv_rf = {}\n",
    "    \n",
    "    param_cv_rf = { 'max_depth'         :[3,4,5,6,7,8,9,None],\n",
    "                 #  'min_samples_leaf'  :[20,30,50,75,100,125,150,200,250,300],\n",
    "                 #  'min_samples_split' :[50,100.150,200,250,300,400,500,600,700],\n",
    "                    'max_features'      :[2,3],\n",
    "                    'n_estimators'      :[50],\n",
    "                    'learning_rate'     :[0.1,0.2,0.3],\n",
    "                    'min_child_weight'  :[0.3,0.5,0,0.6,0.8,1]\n",
    "                  }\n",
    "    \n",
    "    scoring  = ( 'accuracy' , 'precision' , 'recall' , 'f1')\n",
    "\n",
    "    xcb_result = GridSearchCV(xcb_cv,param_cv_rf, scoring=scoring, cv=5,refit ='f1')\n",
    "    return(xcb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_data(df_split_1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X= df_split_1.drop(['Survived'],axis=1)\n",
    "    y=df_split_1['Survived']\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,stratify=y,random_state=32)\n",
    "    \n",
    "    return(X_train,X_test,y_train,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
