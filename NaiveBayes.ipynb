{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDA_NaiveBayes(nb_table_1) :\n",
    "    ##DropColumns if necessary\n",
    "    nb_table=nb_table_1.drop(['Cabin'],axis=1)\n",
    "    nb_table= nb_table.dropna()\n",
    "    print(\"Naive Bayes EDA output shape = \\n\",nb_table.isna().sum())\n",
    "    print(\"Naive Bayes : EDA - Complete \\n\")\n",
    "    return(nb_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureEngineering_NaiveBayes(df_nb_fe) :\n",
    "    ## Feature Selection (\"Drop/Multipy/Create new features/predictors if needed\")\n",
    "    print(\"Naive Bayes : Feature Engineering \\n\")\n",
    "\n",
    "    print(\"Selected predictors for transformation\\n\")\n",
    "    #Feature transformation \n",
    "    #Convert to string (change datatype)\n",
    "    df_nb_fe['Pclass']= df_nb_fe['Pclass'].astype('str')  \n",
    "    #Dummy encode the data\n",
    "    df_nb_fe = pd.get_dummies(df_nb_fe,drop_first=True)\n",
    "    print(\"Check if categorical variables are in string or dummy encoded \\n\",df_nb_fe.columns,\"\\n\")\n",
    "\n",
    "    #Feature Selection\n",
    "    #Based on the correlation Matrix\n",
    "    # Fare has significan positive correlation on Survival\n",
    "    # Sex_male and Pclass has significant negative correlation on survival\n",
    "    # So lets select Fare and Sex_Male for our modelling\n",
    "    \n",
    "    #df_nb_fe_selected = df_nb_fe.drop(['Embarked_S'],axis=1)\n",
    "    df_nb_fe_selected = df_nb_fe\n",
    "    print(\"Selected predictors for modelling \\n\")\n",
    "    print(df_nb_fe_selected.info(),\"\\n\")\n",
    "    return(df_nb_fe_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Important Hyperparameters for Naive Bayes**\n",
    "\n",
    "1. max_depth       : Speciefies how many levels your tree can have, and ultimately determines how many splits it can make.\n",
    "2. min_samples_leaf: Defines the minimum number of samples for a leaf node. i.e. A split can only occur if it guarantees a minimun number of observations in the resulting nodes.\n",
    "3. max_features    : Controls the randomness, It specifies the number of features that each tree randomly selects during training\n",
    "4. n_estimatiors   :  Specifies the number of trees your model will build in its ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HyperParameterTuning_NaiveBayes() :\n",
    "    from sklearn.tree import NaiveBayesClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    nb_cv = NaiveBayesClassifier(random_state=0)\n",
    "    print('Naive Bayes : Hyperparameter Tuning ')   \n",
    "    param_cv_nb = { 'max_depth'         :[2],\n",
    "                    'min_samples_leaf'  :[5],\n",
    "                    'min_samples_split' :[0.3],\n",
    "                    'max_features'      :[2,3]\n",
    "                  }\n",
    "    \n",
    "     \n",
    "  #  param_cv_nb = {}#'max_depth'     :[None],\n",
    "                    #'min_samples_leaf'  :[],\n",
    "                    #'min_samples_split' :[],\n",
    "                    #'max_features'      :[],\n",
    "                    #'n_estimators'      :[]\n",
    "    #              }\n",
    "\n",
    "    scoring  = ( 'accuracy' , 'precision' , 'recall' , 'f1')\n",
    "\n",
    "    nb_result = GridSearchCV(nb_cv,param_cv_nb, scoring=scoring, cv=5,refit ='f1')\n",
    "    return(nb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split_data(df_split_1):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X= df_split_1.drop(['Survived'],axis=1)\n",
    "    y=df_split_1['Survived']\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,stratify=y,random_state=11)\n",
    "    \n",
    "    return(X_train,X_test,y_train,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
